{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ec3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ========= 0. Setup device and threading =========\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "\n",
    "# Device setup: use CUDA if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == 'cuda':\n",
    "    # enable cudnn autotuner (useful if input sizes are stable)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "# Optionally control threads for CPU-bound parts\n",
    "torch.set_num_threads(8)  # uncomment and tune if CPU is the bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a512cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 1. ËØªÂèñÂπ∂Ëß£ÊûêËæìÂÖ• =========\n",
    "# df = pd.read_csv(\"../pymochi_catal_nostop_dataset_weighted.tsv\", sep=\"\\t\")  # ‰Ω†ÁöÑËæìÂÖ•Ë°®\n",
    "df = pd.read_csv(\"../pymochi_stab_dataset_weighted.tsv\", sep=\"\\t\")\n",
    "wt_seq = df.loc[df[\"WT\"] == True, \"aa_seq\"].values[0]\n",
    "mut_seqs = df[\"aa_seq\"].values\n",
    "# add column\n",
    "df[\"fitness\"]=1/(1+np.exp(df[\"ddG\"].values))\n",
    "# fitness = torch.tensor(df[\"fitness\"].values, dtype=torch.float32)\n",
    "fitness = torch.tensor(df[\"fitness\"].values, dtype=torch.float32)\n",
    "# sigma = torch.tensor(df[\"sigma\"].values, dtype=torch.float32)\n",
    "weight = torch.tensor(df[\"weight\"].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6861cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 2. ÊâæÂá∫ÊâÄÊúâÁ™ÅÂèòÁ±ªÂûã =========\n",
    "\n",
    "# find single mutations\n",
    "def find_mutations(seq, wt):\n",
    "    return [(i, wt[i], seq[i]) for i in range(len(wt)) if seq[i] != wt[i]]\n",
    "\n",
    "all_mutations = sorted(list({\n",
    "    (i, wt_seq[i], s[i]) \n",
    "    for s in mut_seqs \n",
    "    for i in range(len(wt_seq)) \n",
    "    if s[i] != wt_seq[i]\n",
    "}))\n",
    "\n",
    "mut_to_idx = {m: k for k, m in enumerate(all_mutations)}\n",
    "M = len(all_mutations)  # ÁâπÂæÅÊï∞\n",
    "N = len(df)\n",
    "\n",
    "# find all mutation pairs for mutantation sequences with >1 mutation site\n",
    "# e.g. for a sequence with 5 different sites, we have 10 pairs\n",
    "def find_mutation_pairs(seq, wt):\n",
    "    muts = find_mutations(seq, wt)\n",
    "    pairs = []\n",
    "    for i in range(len(muts)):\n",
    "        for j in range(i + 1, len(muts)):\n",
    "            pairs.append((muts[i], muts[j]))\n",
    "    return pairs\n",
    "all_mutation_pairs = sorted(list({\n",
    "    pair\n",
    "    for s in mut_seqs\n",
    "    for pair in find_mutation_pairs(s, wt_seq)\n",
    "}))\n",
    "\n",
    "# remove duplicate pairs like ((0,'A','C'),(1,'G','T')) and ((1,'G','T'),(0,'A','C'))\n",
    "all_mutation_pairs = [tuple(sorted(p)) for p in all_mutation_pairs]\n",
    "all_mutation_pairs = sorted(list(set(all_mutation_pairs)))\n",
    "pair_to_idx = {p: k for k, p in enumerate(all_mutation_pairs)}\n",
    "P = len(all_mutation_pairs)  # ‰∫åÈò∂ÁâπÂæÅÊï∞\n",
    "print(f\"Number of features (M) = {M}, Number of total pairwise features (P) = {P}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2282169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 3. ÊûÑÈÄ† one-hot ÁâπÂæÅÁü©Èòµ =========\n",
    "\n",
    "# A. single mutation features\n",
    "X = torch.zeros((N, M), dtype=torch.float32)\n",
    "for n, seq in enumerate(mut_seqs):\n",
    "    for m in find_mutations(seq, wt_seq):\n",
    "        X[n, mut_to_idx[m]] = 1.0\n",
    "\n",
    "# B. mutation pair features - build sparse representation to avoid huge dense allocation\n",
    "\n",
    "# ---------- Step 1: ÁªüËÆ°ÊØè‰∏™pairÁöÑÂá∫Áé∞Ê¨°Êï∞ ----------\n",
    "pair_counts = Counter()\n",
    "for seq in mut_seqs:\n",
    "    for p in find_mutation_pairs(seq, wt_seq):\n",
    "        p = tuple(sorted(p))\n",
    "        pair_counts[p] += 1\n",
    "\n",
    "# ---------- Step 2: Á≠õÈÄâÂá∫Áé∞Ê¨°Êï∞ >= min_support ÁöÑpair ----------\n",
    "min_support = 3  # ÂèØ‰ª•Ë∞ÉÊï¥ÈòàÂÄºÔºåÊØîÂ¶Ç3Êàñ5\n",
    "filtered_pairs = [p for p, c in pair_counts.items() if c >= min_support]\n",
    "pair_to_idx = {p: i for i, p in enumerate(filtered_pairs)}\n",
    "P = len(filtered_pairs)\n",
    "\n",
    "print(f\"Number of filtered pairs kept: {P} / {len(pair_counts)} (min_support={min_support})\")\n",
    "\n",
    "# ---------- Step 3: ÊûÑÂª∫Á®ÄÁñèË°®Á§∫ ----------\n",
    "row_idx, col_idx, vals = [], [], []\n",
    "for n, seq in enumerate(mut_seqs):\n",
    "    for p in find_mutation_pairs(seq, wt_seq):\n",
    "        p = tuple(sorted(p))\n",
    "        idx = pair_to_idx.get(p)\n",
    "        if idx is None:\n",
    "            continue  # Ë¢´ËøáÊª§ÊéâÁöÑpair‰∏ç‰ºöÂä†ÂÖ•Áü©Èòµ\n",
    "        row_idx.append(n)\n",
    "        col_idx.append(idx)\n",
    "        vals.append(1.0)\n",
    "\n",
    "# ---------- Step 4: ËΩ¨ÊàêÁ®ÄÁñèÂº†Èáè ----------\n",
    "if len(row_idx) == 0:\n",
    "    X_pair = torch.zeros((N, 0), dtype=torch.float32)\n",
    "else:\n",
    "    indices = torch.tensor([row_idx, col_idx], dtype=torch.long)\n",
    "    values = torch.tensor(vals, dtype=torch.float32)\n",
    "    X_pair = torch.sparse_coo_tensor(indices, values, size=(N, P))\n",
    "    X_pair = X_pair.coalesce()\n",
    "    print(f\"Constructed sparse X_pair with nnz={X_pair._nnz()}\")\n",
    "\n",
    "# print(f\"N={N}, P={P}\")\n",
    "# row_idx = []\n",
    "# col_idx = []\n",
    "# vals = []\n",
    "# for n, seq in enumerate(mut_seqs):\n",
    "#     for p in find_mutation_pairs(seq, wt_seq):\n",
    "#         p = tuple(sorted(p))\n",
    "#         idx = pair_to_idx.get(p)\n",
    "#         if idx is None:\n",
    "#             continue\n",
    "#         row_idx.append(n)\n",
    "#         col_idx.append(idx)\n",
    "#         vals.append(1.0)\n",
    "\n",
    "# # convert to tensors\n",
    "# if len(row_idx) == 0:\n",
    "#     # fallback to a small dense tensor if no pairs exist\n",
    "#     X_pair = torch.zeros((N, 0), dtype=torch.float32)\n",
    "# else:\n",
    "#     indices = torch.tensor([row_idx, col_idx], dtype=torch.long)  # shape (2, nnz)\n",
    "#     values = torch.tensor(vals, dtype=torch.float32)\n",
    "#     X_pair = torch.sparse_coo_tensor(indices, values, size=(N, P))  # sparse tensor (N, P)\n",
    "#     X_pair = X_pair.coalesce()  # ensure unique indices\n",
    "#     print(f\"Constructed sparse X_pair with nnz={X_pair._nnz()}\")\n",
    "\n",
    "# Move tensors to device (dense tensors to device; sparse move supported in newer torch)\n",
    "X = X.to(device)\n",
    "try:\n",
    "    X_pair = X_pair.to(device)\n",
    "except Exception as e:\n",
    "    print(\"Warning: could not move sparse X_pair to device:\", e)\n",
    "    # keep X_pair on CPU; sparse CUDA support may depend on PyTorch build\n",
    "\n",
    "fitness = fitness.to(device)\n",
    "weight = weight.to(device)\n",
    "# check X\n",
    "print(X.shape)  # (N, M)\n",
    "print(X.sum(dim=1))\n",
    "print(X.sum(dim=0))  # check feature distribution\n",
    "print(X[0])  # first row\n",
    "print(X[:, 0])  # first column\n",
    "\n",
    "# check X_pair\n",
    "print(X_pair.shape)  # (N, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ede74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 4. ÂÆö‰πâÊ®°Âûã =========\n",
    "class MoCHI_Core(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Parameter(torch.zeros(n_features))  # additive coefficients\n",
    "        self.phi0 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.g = nn.Sequential(  # global epistasis (sum of sigmoids)\n",
    "            nn.Linear(1, 20),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "        self.a = nn.Parameter(torch.tensor(1.0))\n",
    "        self.b = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, X):\n",
    "        phi = self.phi0 + X @ self.theta\n",
    "        p = self.g(phi.unsqueeze(1)).squeeze(1)\n",
    "        yhat = self.a * p + self.b\n",
    "        return yhat, phi\n",
    "\n",
    "class MoCHI_TwoState_order1(nn.Module):\n",
    "    def __init__(self, M, R=8.314, T=303.0):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Parameter(torch.zeros(M))\n",
    "        self.phi0 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.a = nn.Parameter(torch.tensor(1.0))\n",
    "        self.b = nn.Parameter(torch.tensor(0.0))\n",
    "        self.R = R\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, X):\n",
    "        phi = self.phi0 + X @ self.theta             # (N,)\n",
    "        z = torch.clamp(phi / (self.R * self.T), -50, 50)\n",
    "        p = 1.0 / (1.0 + torch.exp(z))\n",
    "        yhat = self.a * p + self.b\n",
    "        return yhat, phi\n",
    "\n",
    "class MoCHI_TwoState_order2(nn.Module):\n",
    "    def __init__(self, M, P, R=8.314, T=303.0):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Parameter(torch.zeros(M))\n",
    "        self.phi0 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.phi_pair = nn.Parameter(torch.zeros(P))\n",
    "        self.a = nn.Parameter(torch.tensor(1.0))\n",
    "        self.b = nn.Parameter(torch.tensor(0.0))\n",
    "        self.R = R\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, X, X_pair):\n",
    "        # Accept dense or sparse X_pair. If sparse, use efficient sparse mm\n",
    "        phi = self.phi0 + X @ self.theta\n",
    "        if getattr(X_pair, 'is_sparse', False):\n",
    "            phi_pair_vec = self.phi_pair.unsqueeze(1)  # (P,1)\n",
    "            # Sparse operations don't support autocast, so we need to disable it temporarily\n",
    "            if torch.is_autocast_enabled():\n",
    "                with torch.amp.autocast(device_type='cuda', enabled=False):\n",
    "                    pair_term = torch.sparse.mm(X_pair, phi_pair_vec).squeeze(1)\n",
    "            else:\n",
    "                pair_term = torch.sparse.mm(X_pair, phi_pair_vec).squeeze(1)\n",
    "        else:\n",
    "            pair_term = X_pair @ self.phi_pair\n",
    "        phi = phi + pair_term  # (N,)\n",
    "        z = torch.clamp(phi / (self.R * self.T), -50, 50)\n",
    "        p = 1.0 / (1.0 + torch.exp(z))\n",
    "        yhat = self.a * p + self.b\n",
    "        return yhat, phi\n",
    "\n",
    "\n",
    "class Linear_order2(nn.Module):\n",
    "    \"\"\"\n",
    "    Á∫øÊÄßÊ®°ÂûãÔºöyhat = phi0 + X @ theta + X_pair @ phi_pair\n",
    "    \"\"\"\n",
    "    def __init__(self, M, P):\n",
    "        super().__init__()\n",
    "        self.phi0 = nn.Parameter(torch.zeros(1))\n",
    "        self.theta = nn.Parameter(torch.zeros(M))\n",
    "        self.phi_pair = nn.Parameter(torch.zeros(P))\n",
    "\n",
    "    def forward(self, X, X_pair):\n",
    "        # ÁÆÄÂçïÁöÑÁ∫øÊÄßÈ¢ÑÊµãÔºöyhat = phi0 + X @ theta + X_pair @ phi_pair\n",
    "        yhat = self.phi0 + X @ self.theta\n",
    "        \n",
    "        if getattr(X_pair, 'is_sparse', False):\n",
    "            phi_pair_vec = self.phi_pair.unsqueeze(1)\n",
    "            if torch.is_autocast_enabled():\n",
    "                with torch.amp.autocast(device_type='cuda', enabled=False):\n",
    "                    pair_term = torch.sparse.mm(X_pair, phi_pair_vec).squeeze(1)\n",
    "            else:\n",
    "                pair_term = torch.sparse.mm(X_pair, phi_pair_vec).squeeze(1)\n",
    "        else:\n",
    "            pair_term = X_pair @ self.phi_pair\n",
    "        \n",
    "        yhat = yhat + pair_term\n",
    "        return yhat\n",
    "\n",
    "\n",
    "class Linear_order1(nn.Module):\n",
    "    \"\"\"\n",
    "    ‰ªÖ‰ΩøÁî®ÂçïÁ™ÅÂèòÁöÑÁ∫øÊÄßÊ®°ÂûãÔºöyhat = phi0 + X @ theta\n",
    "    Áî® LASSO Âú®ÂçïÁ™ÅÂèòÁâπÂæÅ‰∏äÊ±ÇËß£Á®ÄÁñè theta (‰∏çÂåÖÂê´ pairwise)\n",
    "    \"\"\"\n",
    "    def __init__(self, M):\n",
    "        super().__init__()\n",
    "        self.phi0 = nn.Parameter(torch.zeros(1))\n",
    "        self.theta = nn.Parameter(torch.zeros(M))\n",
    "\n",
    "    def forward(self, X):\n",
    "        yhat = self.phi0 + X @ self.theta\n",
    "        return yhat\n",
    "\n",
    "\n",
    "# instantiate and move models to device\n",
    "model1 = MoCHI_TwoState_order1(M).to(device)\n",
    "model2 = MoCHI_TwoState_order2(M, P).to(device)\n",
    "model_linear = Linear_order2(M, P).to(device)\n",
    "# new: linear model using only single-mutation features\n",
    "model_linear1 = Linear_order1(M).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 4.5 Á∫øÊÄßÊ®°ÂûãÊ±ÇËß£ÔºàLASSOÔºâ=========\n",
    "# ÂØπ‰∫é Linear_order2 Ê®°ÂûãÔºåÂèØ‰ª•Áî®LASSOÁõ¥Êé•Ê±ÇËß£ÔºåÊó†ÈúÄËø≠‰ª£‰ºòÂåñ\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Linear Model (Linear_order2) - LASSO Solution\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ËΩ¨Êç¢‰∏∫ sparse Ê†ºÂºèÔºà‰∏çËΩ¨ denseÔºÅÔºâ\n",
    "X_np = X.cpu().numpy()  # (N, M)\n",
    "X_np_sparse = csr_matrix(X_np)  # ËΩ¨‰∏∫ sparse format\n",
    "\n",
    "# Â§ÑÁêÜÁ®ÄÁñèÁü©ÈòµÔºàÂèØËÉΩÂú®GPUÊàñCPU‰∏äÔºâ\n",
    "# ‚ö†Ô∏è ÂÖ≥ÈîÆÔºö‰øùÊåÅ sparse formatÔºå‰∏çËΩ¨ denseÔºÅ\n",
    "if getattr(X_pair, 'is_sparse', False):\n",
    "    # ‰ªé PyTorch sparse tensor ÊèêÂèñÊï∞ÊçÆÔºåÊûÑÂª∫ scipy sparse\n",
    "    X_pair_cpu = X_pair.cpu()\n",
    "    indices = X_pair_cpu._indices().numpy()\n",
    "    values = X_pair_cpu._values().numpy()\n",
    "    shape = X_pair_cpu.shape\n",
    "    X_pair_sparse = csr_matrix((values, (indices[0], indices[1])), shape=shape)\n",
    "    print(f\"  Built sparse X_pair with shape {shape}, nnz={len(values)}\")\n",
    "else:\n",
    "    X_pair_sparse = csr_matrix(X_pair.cpu().numpy())\n",
    "\n",
    "fitness_np = fitness.cpu().numpy()  # (N,)\n",
    "weight_np = weight.cpu().numpy()  # (N,)\n",
    "\n",
    "print(f\"\\nFeature dimensions:\")\n",
    "print(f\"  X shape: {X_np.shape} (single mutations)\")\n",
    "print(f\"  X_pair shape: {X_pair_sparse.shape} (pairwise interactions)\")\n",
    "print(f\"  Combined features: {X_np.shape[1] + X_pair_sparse.shape[1] + 1} (including phi0)\")\n",
    "\n",
    "# ÁªÑÂêàÁâπÂæÅÁü©ÈòµÔºö[ones | X | X_pair]Ôºå‰øùÊåÅ sparse Ê†ºÂºè\n",
    "ones = csr_matrix(np.ones((N, 1)))\n",
    "X_combined = hstack([ones, X_np_sparse, X_pair_sparse])  # ‰øùÊåÅ sparse\n",
    "\n",
    "# ‚ö†Ô∏è ÊîπËøõÔºö‰∏çÂú®fit‰∏≠Â∫îÁî®Âä†ÊùÉÔºåËÄåÊòØÂú®lossËÆ°ÁÆó‰∏≠Â∫îÁî®Âä†ÊùÉ\n",
    "# ËøôÊ†∑ÂèØ‰ª•ÈÅøÂÖçËøáÂ∫¶Ê≠£ÂàôÂåñÂØºËá¥ÂèÇÊï∞ÂÖ®ÂèòÈõ∂\n",
    "print(f\"  Feature matrix (unweighted): {X_combined.shape} (sparse)\")\n",
    "\n",
    "# Â∞ùËØïÂ§ö‰∏™ alpha ÂÄº - ÈúÄË¶ÅÊõ¥Â∞èÁöÑalpha‰ª•ÈÅøÂÖçËøáÂ∫¶Ê≠£ÂàôÂåñ\n",
    "alphas = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "lasso_results = {}\n",
    "\n",
    "print(f\"\\nTraining LASSO with different alpha values...\\n\")\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000, tol=1e-6, fit_intercept=False)\n",
    "    # Âú®ÂéüÂßãÔºàÊú™Âä†ÊùÉÔºâÊï∞ÊçÆ‰∏äfit\n",
    "    lasso.fit(X_combined, fitness_np)\n",
    "    coef = lasso.coef_\n",
    "    \n",
    "    # ÊèêÂèñÂèÇÊï∞\n",
    "    phi0_sol = coef[0]\n",
    "    theta_sol = coef[1:1+M]\n",
    "    phi_pair_sol = coef[1+M:1+M+P]\n",
    "    \n",
    "    # ËÆ°ÁÆóÈ¢ÑÊµãÂíåÂä†ÊùÉÊçüÂ§±\n",
    "    yhat_linear = phi0_sol + X_np @ theta_sol + X_pair_sparse.dot(phi_pair_sol)\n",
    "    residual = fitness_np - yhat_linear\n",
    "    # Âä†ÊùÉÊçüÂ§±\n",
    "    weighted_mae = np.mean(np.abs(residual * weight_np))\n",
    "    \n",
    "    # ËÆ°ÁÆóÁ®ÄÁñèÂ∫¶\n",
    "    nnz_theta = np.count_nonzero(np.abs(theta_sol) > 1e-10)\n",
    "    nnz_phi_pair = np.count_nonzero(np.abs(phi_pair_sol) > 1e-10)\n",
    "    sparsity_phi_pair = 100 * (1 - nnz_phi_pair / len(phi_pair_sol))\n",
    "    \n",
    "    # ËÆ°ÁÆó L1 ËåÉÊï∞\n",
    "    l1_theta = np.sum(np.abs(theta_sol))\n",
    "    l1_phi_pair = np.sum(np.abs(phi_pair_sol))\n",
    "    \n",
    "    lasso_results[alpha] = {\n",
    "        'phi0': phi0_sol,\n",
    "        'theta': theta_sol,\n",
    "        'phi_pair': phi_pair_sol,\n",
    "        'loss': weighted_mae,\n",
    "        'nnz_theta': nnz_theta,\n",
    "        'nnz_phi_pair': nnz_phi_pair,\n",
    "        'sparsity_phi_pair': sparsity_phi_pair,\n",
    "        'l1_theta': l1_theta,\n",
    "        'l1_phi_pair': l1_phi_pair\n",
    "    }\n",
    "    \n",
    "    print(f\"alpha = {alpha:8.2e} | Loss = {weighted_mae:.6f} | \" +\n",
    "          f\"NNZ(theta)={nnz_theta:4d} | NNZ(phi_pair)={nnz_phi_pair:5d} | \" +\n",
    "          f\"Sparsity={sparsity_phi_pair:5.1f}%\")\n",
    "\n",
    "# ÊâæÂà∞ÊçüÂ§±ÊúÄÂ∞èÁöÑÊ®°Âûã\n",
    "best_alpha = min(lasso_results.keys(), key=lambda a: lasso_results[a]['loss'])\n",
    "best_result = lasso_results[best_alpha]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Best LASSO solution: alpha = {best_alpha}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Loss (Weighted MAE): {best_result['loss']:.6f}\")\n",
    "print(f\"Parameters:\")\n",
    "print(f\"  phi0: {best_result['phi0']:.6f}\")\n",
    "print(f\"  theta: NNZ={best_result['nnz_theta']}, ||theta||_1={best_result['l1_theta']:.4f}\")\n",
    "print(f\"  phi_pair: NNZ={best_result['nnz_phi_pair']}, Sparsity={best_result['sparsity_phi_pair']:.2f}%, \" +\n",
    "      f\"||phi_pair||_1={best_result['l1_phi_pair']:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Â∞ÜÊúÄ‰Ω≥ÂèÇÊï∞Âä†ËΩΩÂà∞Ê®°Âûã\n",
    "with torch.no_grad():\n",
    "    model_linear.phi0.data = torch.tensor([best_result['phi0']], dtype=torch.float32, device=device)\n",
    "    model_linear.theta.data = torch.tensor(best_result['theta'], dtype=torch.float32, device=device)\n",
    "    model_linear.phi_pair.data = torch.tensor(best_result['phi_pair'], dtype=torch.float32, device=device)\n",
    "\n",
    "print(\"\\n‚úì LASSO parameters loaded to model_linear\")\n",
    "\n",
    "# ========= 4.6b Á∫øÊÄßÊ®°ÂûãÔºàÂçïÁ™ÅÂèòÔºâÊ±ÇËß£ - Linear_order1 (LASSO) =========\n",
    "print('\\n' + '='*60)\n",
    "print('Linear Model (Linear_order1) - LASSO Solution (single mutations only)')\n",
    "print('='*60)\n",
    "\n",
    "X_single_sparse = X_np_sparse  # csr_matrix of shape (N, M)\n",
    "X1_combined = hstack([ones, X_single_sparse])\n",
    "\n",
    "lasso1_results = {}\n",
    "print('\\nTraining LASSO (single-mutation only) with different alpha values...\\n')\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso1 = Lasso(alpha=alpha, max_iter=10000, tol=1e-6, fit_intercept=False)\n",
    "    # Âú®ÂéüÂßãÊï∞ÊçÆ‰∏äfitÔºà‰∏çÂä†ÊùÉÔºâ\n",
    "    lasso1.fit(X1_combined, fitness_np)\n",
    "    coef1 = lasso1.coef_\n",
    "    phi01 = coef1[0]\n",
    "    theta1 = coef1[1:1+M]\n",
    "    \n",
    "    # ËÆ°ÁÆóÂä†ÊùÉÊçüÂ§±\n",
    "    yhat1 = phi01 + X_np @ theta1\n",
    "    residual1 = fitness_np - yhat1\n",
    "    weighted_mae1 = np.mean(np.abs(residual1 * weight_np))\n",
    "    \n",
    "    nnz_theta1 = np.count_nonzero(np.abs(theta1) > 1e-10)\n",
    "    l1_theta1 = np.sum(np.abs(theta1))\n",
    "    lasso1_results[alpha] = { 'phi0': phi01, 'theta': theta1, 'loss': weighted_mae1, 'nnz_theta': nnz_theta1, 'l1_theta': l1_theta1 }\n",
    "    print(f\"alpha = {alpha:8.2e} | Loss = {weighted_mae1:.6f} | NNZ(theta)={nnz_theta1:4d}\")\n",
    "\n",
    "# choose best\n",
    "best_alpha1 = min(lasso1_results.keys(), key=lambda a: lasso1_results[a]['loss'])\n",
    "best_result1 = lasso1_results[best_alpha1]\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print(f'Best LASSO (single) alpha = {best_alpha1}')\n",
    "print(f\"Loss (Weighted MAE): {best_result1['loss']:.6f}\")\n",
    "print('\\nLoading parameters into model_linear1...')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_linear1.phi0.data = torch.tensor([best_result1['phi0']], dtype=torch.float32, device=device)\n",
    "    model_linear1.theta.data = torch.tensor(best_result1['theta'], dtype=torch.float32, device=device)\n",
    "\n",
    "print('\\n‚úì LASSO (single) parameters loaded to model_linear1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4cb20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 5. ËÆ≠ÁªÉËÆæÁΩÆ =========\n",
    "\n",
    "optimizer1 = optim.Adam(params=model1.parameters(), lr=0.05)\n",
    "optimizer2 = optim.Adam(params=model2.parameters(), lr=0.05)\n",
    "\n",
    "lambda_l1 = 1e-8  # L1 penalty factor for phi_pair\n",
    "n_epochs = 30000\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 500\n",
    "min_delta = 1e-5\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "stopped_early = False\n",
    "\n",
    "# Setup mixed precision training if using CUDA\n",
    "use_amp = (device.type == 'cuda')\n",
    "scaler1 = torch.amp.GradScaler('cuda') if use_amp else None\n",
    "scaler2 = torch.amp.GradScaler('cuda') if use_amp else None\n",
    "\n",
    "# Initialize loss history tracking\n",
    "loss_history1 = []\n",
    "loss_history2 = []\n",
    "data_loss_history = []\n",
    "l1_loss_history = []\n",
    "epoch_list = []\n",
    "\n",
    "# ========= Order 1 Training =========\n",
    "print(\"=\" * 60)\n",
    "print(\"Training Order 1 Model (Single Mutations Only)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_loss1 = float('inf')\n",
    "patience_counter1 = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer1.zero_grad()\n",
    "    \n",
    "    # Mixed precision forward pass\n",
    "    if use_amp:\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            yhat, phi = model1(X)\n",
    "            loss = torch.mean(torch.abs((fitness - yhat) * weight))\n",
    "        # Scaled backward pass\n",
    "        scaler1.scale(loss).backward()\n",
    "        scaler1.step(optimizer1)\n",
    "        scaler1.update()\n",
    "    else:\n",
    "        yhat, phi = model1(X)\n",
    "        loss = torch.mean(torch.abs((fitness - yhat) * weight))\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "    \n",
    "    # Record loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        loss_history1.append(loss.item())\n",
    "        if epoch == 0:\n",
    "            epoch_list.append(epoch)\n",
    "    \n",
    "    # Early stopping check\n",
    "    current_loss = loss.item()\n",
    "    if current_loss < best_loss1 * (1 - min_delta):\n",
    "        best_loss1 = current_loss\n",
    "        patience_counter1 = 0\n",
    "    else:\n",
    "        patience_counter1 += 1\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        phi_range = f\"[{phi.min().item():.2f}, {phi.max().item():.2f}]\"\n",
    "        print(f\"Epoch {epoch:4d} | Loss = {loss.item():.5f} | phi_range = {phi_range} | patience = {patience_counter1}/{patience}\")\n",
    "    \n",
    "    if patience_counter1 >= patience:\n",
    "        print(f\"\\n>>> Early stopping triggered at epoch {epoch}\")\n",
    "        print(f\">>> Best loss: {best_loss1:.5f}, Current loss: {current_loss:.5f}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training Order 2 Model (Single Mutations + Pairs)\")\n",
    "print(f\"L1 regularization: lambda_l1={lambda_l1}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========= Order 2 Training =========\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer2.zero_grad()\n",
    "    \n",
    "    # Mixed precision forward pass\n",
    "    if use_amp:\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            yhat, phi = model2(X, X_pair)\n",
    "            data_loss = torch.mean(torch.abs((fitness - yhat) * weight))\n",
    "            l1_penalty = lambda_l1 * torch.norm(model2.phi_pair, p=1)\n",
    "            loss = data_loss + l1_penalty\n",
    "        # Scaled backward pass\n",
    "        scaler2.scale(loss).backward()\n",
    "        scaler2.step(optimizer2)\n",
    "        scaler2.update()\n",
    "    else:\n",
    "        yhat, phi = model2(X, X_pair)\n",
    "        data_loss = torch.mean(torch.abs((fitness - yhat) * weight))\n",
    "        l1_penalty = lambda_l1 * torch.norm(model2.phi_pair, p=1)\n",
    "        loss = data_loss + l1_penalty\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "    \n",
    "    # Record loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        loss_history2.append(loss.item())\n",
    "        data_loss_history.append(data_loss.item())\n",
    "        l1_loss_history.append(l1_penalty.item())\n",
    "        if len(epoch_list) < len(loss_history2):\n",
    "            epoch_list.append(epoch)\n",
    "    \n",
    "    # Early stopping based on data_loss only\n",
    "    current_data_loss = data_loss.item()\n",
    "    if current_data_loss < best_loss * (1 - min_delta):\n",
    "        best_loss = current_data_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        phi_pair_norm = torch.norm(model2.phi_pair, p=1).item()\n",
    "        nnz_phi_pair = int((torch.abs(model2.phi_pair) > 1e-10).sum().item())\n",
    "        sparsity_pct = 100.0 * (1.0 - nnz_phi_pair / model2.phi_pair.numel())\n",
    "        print(f\"Epoch {epoch:4d} | Total={loss.item():.5f} | Data={data_loss.item():.5f} | L1={l1_penalty.item():.5f}\")\n",
    "        print(f\"              ||phi_pair||_1={phi_pair_norm:.4f} | NNZ={nnz_phi_pair} | Sparsity={sparsity_pct:.1f}% | patience={patience_counter}/{patience}\")\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\">>> Early stopping triggered at epoch {epoch}\")\n",
    "        print(f\">>> Best data loss: {best_loss:.5f}, Current: {current_data_loss:.5f}\")\n",
    "        print(f\">>> No improvement for {patience} consecutive epochs\")\n",
    "        print(f\"{'='*60}\")\n",
    "        stopped_early = True\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if stopped_early:\n",
    "    print(f\"Training stopped early at epoch {epoch}/{n_epochs}\")\n",
    "else:\n",
    "    print(\"Training completed all epochs!\")\n",
    "print(f\"Final data loss: {data_loss.item():.5f}\")\n",
    "print(f\"Final L1 penalty: {l1_penalty.item():.5f}\")\n",
    "print(f\"Final total loss: {loss.item():.5f}\")\n",
    "\n",
    "# Final sparsity analysis\n",
    "final_nnz = int((torch.abs(model2.phi_pair) > 1e-10).sum().item())\n",
    "final_sparsity = 100.0 * (1.0 - final_nnz / model2.phi_pair.numel())\n",
    "print(f\"Final phi_pair non-zeros: {final_nnz} / {model2.phi_pair.numel()} ({final_sparsity:.2f}% sparse)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 5.5 ËÆ≠ÁªÉËøáÁ®ãÂèØËßÜÂåñ =========\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create epoch lists for each model based on actual recorded losses\n",
    "epoch_list1 = list(range(0, len(loss_history1) * 10, 10)) if loss_history1 else []\n",
    "epoch_list2 = list(range(0, len(loss_history2) * 10, 10))\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Total loss curves comparison\n",
    "ax1 = axes[0, 0]\n",
    "if loss_history1:\n",
    "    ax1.plot(epoch_list1, loss_history1, linewidth=2, color='steelblue', label='Order 1 Model', alpha=0.8)\n",
    "ax1.plot(epoch_list2, loss_history2, linewidth=2, color='coral', label='Order 2 Model (Total)', alpha=0.8)\n",
    "ax1.set_xlabel('Epoch', fontsize=13)\n",
    "ax1.set_ylabel('Loss (Weighted L1)', fontsize=13)\n",
    "ax1.set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Data loss vs L1 penalty decomposition\n",
    "ax2 = axes[0, 1]\n",
    "# ÂøÖÈ°ª‰ΩøÁî®ÂØπÂ∫îÁöÑÈïøÂ∫¶Ôºå‰∏çËÉΩÂÅáËÆæ epoch_list2 Âíå data_loss_history ÈïøÂ∫¶Áõ∏Âêå\n",
    "if data_loss_history and l1_loss_history:\n",
    "    ax2.plot(epoch_list2[:len(data_loss_history)], data_loss_history, linewidth=2, color='green', label='Data Loss', alpha=0.8)\n",
    "    ax2_twin = ax2.twinx()\n",
    "    ax2_twin.plot(epoch_list2[:len(l1_loss_history)], l1_loss_history, linewidth=2, color='red', label='L1 Penalty', alpha=0.8, linestyle='--')\n",
    "    ax2.set_xlabel('Epoch', fontsize=13)\n",
    "    ax2.set_ylabel('Data Loss', fontsize=13, color='green')\n",
    "    ax2_twin.set_ylabel('L1 Penalty', fontsize=13, color='red')\n",
    "    ax2.set_title('Loss Decomposition (Order 2 Model)', fontsize=14, fontweight='bold')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "    ax2_twin.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.legend(loc='upper left', fontsize=12)\n",
    "    ax2_twin.legend(loc='upper right', fontsize=12)\n",
    "    ax2.grid(alpha=0.3)\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'Data loss history not available\\n(training cell needs to complete)', \n",
    "            ha='center', va='center', fontsize=12, transform=ax2.transAxes)\n",
    "    ax2.set_title('Loss Decomposition (Order 2 Model)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 3: Log scale for total loss\n",
    "ax3 = axes[1, 0]\n",
    "if loss_history1:\n",
    "    ax3.semilogy(epoch_list1, loss_history1, linewidth=2, color='steelblue', label='Order 1 Model', alpha=0.8)\n",
    "ax3.semilogy(epoch_list2, loss_history2, linewidth=2, color='coral', label='Order 2 Model (Total)', alpha=0.8)\n",
    "ax3.set_xlabel('Epoch', fontsize=13)\n",
    "ax3.set_ylabel('Loss (Log Scale)', fontsize=13)\n",
    "ax3.set_title('Training Loss Comparison (Log Scale)', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=12)\n",
    "ax3.grid(alpha=0.3, which='both')\n",
    "\n",
    "# Plot 4: Data loss in log scale\n",
    "ax4 = axes[1, 1]\n",
    "ax4.semilogy(epoch_list2[:len(data_loss_history)], data_loss_history, linewidth=2, color='green', label='Data Loss (Order 2)', alpha=0.8)\n",
    "ax4.set_xlabel('Epoch', fontsize=13)\n",
    "ax4.set_ylabel('Data Loss (Log Scale)', fontsize=13)\n",
    "ax4.set_title('Data Loss Only (Log Scale)', fontsize=14, fontweight='bold')\n",
    "ax4.legend(fontsize=12)\n",
    "ax4.grid(alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print training summary\n",
    "print(\"=\" * 60)\n",
    "print(\"Training Summary:\")\n",
    "print(\"=\" * 60)\n",
    "if loss_history1:\n",
    "    print(f\"\\nOrder 1 Model:\")\n",
    "    print(f\"  Total epochs trained: {len(loss_history1) * 10}\")\n",
    "    print(f\"  Initial loss: {loss_history1[0]:.5f}\")\n",
    "    print(f\"  Final loss: {loss_history1[-1]:.5f}\")\n",
    "    print(f\"  Loss reduction: {loss_history1[0] - loss_history1[-1]:.5f} ({(loss_history1[0] - loss_history1[-1])/loss_history1[0]*100:.2f}%)\")\n",
    "print(f\"\\nOrder 2 Model:\")\n",
    "print(f\"  Total epochs trained: {len(loss_history2) * 10}\")\n",
    "print(f\"  Initial total loss: {loss_history2[0]:.5f}\")\n",
    "print(f\"  Final total loss: {loss_history2[-1]:.5f}\")\n",
    "print(f\"  Total loss reduction: {loss_history2[0] - loss_history2[-1]:.5f} ({(loss_history2[0] - loss_history2[-1])/loss_history2[0]*100:.2f}%)\")\n",
    "print(f\"\\n  Initial data loss: {data_loss_history[0]:.5f}\")\n",
    "print(f\"  Final data loss: {data_loss_history[-1]:.5f}\")\n",
    "print(f\"  Data loss reduction: {data_loss_history[0] - data_loss_history[-1]:.5f} ({(data_loss_history[0] - data_loss_history[-1])/data_loss_history[0]*100:.2f}%)\")\n",
    "print(f\"\\n  Initial L1 penalty: {l1_loss_history[0]:.5f}\")\n",
    "print(f\"  Final L1 penalty: {l1_loss_history[-1]:.5f}\")\n",
    "print(f\"  L1 penalty change: {l1_loss_history[-1] - l1_loss_history[0]:.5f}\")\n",
    "if loss_history1:\n",
    "    print(f\"\\nFinal loss comparison:\")\n",
    "    print(f\"  Order 2 vs Order 1: {loss_history2[-1] - loss_history1[-1]:.5f} ({(loss_history2[-1] - loss_history1[-1])/loss_history1[-1]*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828aa849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 7. Ê®°ÂûãÂèÇÊï∞ÂàÜÂ∏ÉÂàÜÊûê =========\n",
    "\n",
    "\n",
    "# Extract parameters from model2\n",
    "theta_values = model2.theta.detach().cpu().numpy()\n",
    "phi_pair_values = model2.phi_pair.detach().cpu().numpy()\n",
    "phi0_value = model2.phi0.item()\n",
    "a_value = model2.a.item()\n",
    "b_value = model2.b.item()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Model Parameters Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"phi0 (baseline): {phi0_value:.4f}\")\n",
    "print(f\"a (scaling): {a_value:.4f}\")\n",
    "print(f\"b (offset): {b_value:.4f}\")\n",
    "print(f\"\\nSingle mutation parameters (theta):\")\n",
    "print(f\"  - Number of features: {len(theta_values)}\")\n",
    "print(f\"  - Range: [{theta_values.min():.4f}, {theta_values.max():.4f}]\")\n",
    "print(f\"  - Mean: {theta_values.mean():.4f}, Std: {theta_values.std():.4f}\")\n",
    "print(f\"  - Non-zero count: {np.count_nonzero(np.abs(theta_values) > 1e-6)}\")\n",
    "print(f\"\\nMutation pair parameters (phi_pair):\")\n",
    "print(f\"  - Number of features: {len(phi_pair_values)}\")\n",
    "print(f\"  - Range: [{phi_pair_values.min():.4f}, {phi_pair_values.max():.4f}]\")\n",
    "print(f\"  - Mean: {phi_pair_values.mean():.4f}, Std: {phi_pair_values.std():.4f}\")\n",
    "print(f\"  - Non-zero count: {np.count_nonzero(np.abs(phi_pair_values) > 1e-6)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Theta distribution (histogram)\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(theta_values, bins=100, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax1.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "ax1.set_xlabel('Parameter value', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.set_title(f'Single Mutation Parameters (theta)\\nN={len(theta_values)}, Mean={theta_values.mean():.4f}', fontsize=13)\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Phi_pair distribution (histogram)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(phi_pair_values, bins=100, edgecolor='black', alpha=0.7, color='coral')\n",
    "ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "ax2.set_xlabel('Parameter value', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title(f'Mutation Pair Parameters (phi_pair)\\nN={len(phi_pair_values)}, Mean={phi_pair_values.mean():.4f}', fontsize=13)\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Sorted theta values (identify important features)\n",
    "ax3 = axes[1, 0]\n",
    "sorted_theta = np.sort(theta_values)\n",
    "ax3.plot(sorted_theta, linewidth=1.5, color='steelblue', label='Sorted parameters')\n",
    "ax3.fill_between(range(len(sorted_theta)), sorted_theta, 0, alpha=0.3, color='steelblue')\n",
    "ax3.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax3.set_xlabel('Feature index (sorted)', fontsize=12)\n",
    "ax3.set_ylabel('Parameter value', fontsize=12)\n",
    "ax3.set_title(f'Sorted Single Mutation Parameters\\nRange: [{sorted_theta.min():.4f}, {sorted_theta.max():.4f}]', fontsize=13)\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.legend(fontsize=10)\n",
    "\n",
    "# Plot 4: Sorted phi_pair values\n",
    "ax4 = axes[1, 1]\n",
    "sorted_phi_pair = np.sort(phi_pair_values)\n",
    "ax4.plot(sorted_phi_pair, linewidth=1.5, color='coral', label='Sorted parameters')\n",
    "ax4.fill_between(range(len(sorted_phi_pair)), sorted_phi_pair, 0, alpha=0.3, color='coral')\n",
    "ax4.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax4.set_xlabel('Feature index (sorted)', fontsize=12)\n",
    "ax4.set_ylabel('Parameter value', fontsize=12)\n",
    "ax4.set_title(f'Sorted Mutation Pair Parameters\\nRange: [{sorted_phi_pair.min():.4f}, {sorted_phi_pair.max():.4f}]', fontsize=13)\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show top influential parameters\n",
    "print(\"\\nTop 10 most positive single mutations (theta):\")\n",
    "top_positive_theta_idx = np.argsort(theta_values)[-10:][::-1]\n",
    "for i, idx in enumerate(top_positive_theta_idx, 1):\n",
    "    mut = all_mutations[idx]\n",
    "    print(f\"  {i}. Position {mut[0]}: {mut[1]}->{mut[2]}, theta={theta_values[idx]:.4f}\")\n",
    "\n",
    "print(\"\\nTop 10 most negative single mutations (theta):\")\n",
    "top_negative_theta_idx = np.argsort(theta_values)[:10]\n",
    "for i, idx in enumerate(top_negative_theta_idx, 1):\n",
    "    mut = all_mutations[idx]\n",
    "    print(f\"  {i}. Position {mut[0]}: {mut[1]}->{mut[2]}, theta={theta_values[idx]:.4f}\")\n",
    "\n",
    "print(\"\\nTop 10 most positive mutation pairs (phi_pair):\")\n",
    "top_positive_pair_idx = np.argsort(phi_pair_values)[-10:][::-1]\n",
    "for i, idx in enumerate(top_positive_pair_idx, 1):\n",
    "    pair = all_mutation_pairs[idx]\n",
    "    print(f\"  {i}. {pair[0]} & {pair[1]}, phi_pair={phi_pair_values[idx]:.4f}\")\n",
    "\n",
    "print(\"\\nTop 10 most negative mutation pairs (phi_pair):\")\n",
    "top_negative_pair_idx = np.argsort(phi_pair_values)[:10]\n",
    "for i, idx in enumerate(top_negative_pair_idx, 1):\n",
    "    pair = all_mutation_pairs[idx]\n",
    "    print(f\"  {i}. {pair[0]} & {pair[1]}, phi_pair={phi_pair_values[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b52095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: ÂõõÊ®°ÂûãÂØπÊØîÔºàOrder 1, Order 2, Linear pairs, Linear singleÔºâ\n",
    "try:\n",
    "    fig4, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_p1, _ = model1(X)\n",
    "        y_p1 = y_p1.cpu().numpy()\n",
    "        _, phi2 = model2(X, X_pair)\n",
    "        y_p2 = (1.0 / (1.0 + torch.exp(torch.clamp(phi2 / (8.314 * 303.0), -50, 50)))).cpu().numpy()\n",
    "        y_p2 = model2.a.item() * y_p2 + model2.b.item()\n",
    "\n",
    "    r1_tmp, p1_tmp = pearsonr(fitness_np, y_p1)\n",
    "    r2_tmp, p2_tmp = pearsonr(fitness_np, y_p2)\n",
    "\n",
    "    models_data = [\n",
    "        (\"Order 1\\n(Single muts)\", y_p1, r1_tmp),\n",
    "        (\"Order 2\\n(With pairs)\", y_p2, r2_tmp),\n",
    "        (\"Linear\\n(Pairs)\", y_pred_linear, r_linear_calc),\n",
    "        (\"Linear\\n(Single)\", y_pred_linear1_val, r_linear1_calc)\n",
    "    ]\n",
    "\n",
    "    # Compute y-axis limits SEPARATELY for each model to avoid compression\n",
    "    # Store y-limits for each of the 4 models\n",
    "    model_ylims_4 = []\n",
    "    for col, (name, y_pred, r) in enumerate(models_data):\n",
    "        y_min = y_pred.min()\n",
    "        y_max = y_pred.max()\n",
    "        y_margin = (y_max - y_min) * 0.1 if (y_max - y_min) > 0 else 0.1\n",
    "        model_ylims_4.append((y_min - y_margin, y_max + y_margin))\n",
    "\n",
    "    # Top row: hexbin density plots\n",
    "    for col, (name, y_pred, r) in enumerate(models_data):\n",
    "        ax = axes[0, col]\n",
    "        hb = ax.hexbin(fitness_np, y_pred, gridsize=100, cmap='viridis', mincnt=1, edgecolors='none')\n",
    "        ax.plot([fitness_np.min(), fitness_np.max()], [fitness_np.min(), fitness_np.max()], 'r--', linewidth=2, alpha=0.7)\n",
    "        ax.set_xlabel(\"Measured fitness\", fontsize=11)\n",
    "        ax.set_ylabel(\"Predicted fitness\", fontsize=11)\n",
    "        ax.set_title(f\"{name}\\nr={r:.4f}\", fontsize=12, fontweight='bold')\n",
    "        ax.set_xlim(fitness_np.min(), fitness_np.max())\n",
    "        # Use individual model's y-limits for clearer visualization\n",
    "        ax.set_ylim(model_ylims_4[col])\n",
    "        plt.colorbar(hb, ax=ax, label='Density')\n",
    "\n",
    "    # Bottom row: weight-colored scatter plots\n",
    "    for col, (name, y_pred, r) in enumerate(models_data):\n",
    "        ax = axes[1, col]\n",
    "        scatter = ax.scatter(fitness_np, y_pred, c=weight_np, s=2, cmap='plasma', alpha=0.6, edgecolors='none')\n",
    "        ax.plot([fitness_np.min(), fitness_np.max()], [fitness_np.min(), fitness_np.max()], 'r--', linewidth=2, alpha=0.7)\n",
    "        ax.set_xlabel(\"Measured fitness\", fontsize=11)\n",
    "        ax.set_ylabel(\"Predicted fitness\", fontsize=11)\n",
    "        ax.set_title(f\"Weight distribution\", fontsize=11)\n",
    "        ax.set_xlim(fitness_np.min(), fitness_np.max())\n",
    "        # Use individual model's y-limits\n",
    "        ax.set_ylim(model_ylims_4[col])\n",
    "        plt.colorbar(scatter, ax=ax, label='Weight')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig4.savefig(f\"{results_dir}/04_four_models_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì 04_four_models_comparison.png\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save four models comparison figure: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b421b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 8. ‰øùÂ≠òÊâÄÊúâÁªìÊûú =========\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "# ÂàõÂª∫Â∏¶Êó∂Èó¥Êà≥ÁöÑÁªìÊûúÊñá‰ª∂Â§π\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_dir = f\"results_{timestamp}\"\n",
    "\n",
    "# Â¶ÇÊûúÊñá‰ª∂Â§πÂ∑≤Â≠òÂú®ÔºåÂà†Èô§ÂêéÈáçÂª∫\n",
    "if os.path.exists(results_dir):\n",
    "    shutil.rmtree(results_dir)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üìÅ Saving all results to: {results_dir}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ========= Recalculate performance metrics if needed =========\n",
    "print(\"üìà Calculating performance metrics...\")\n",
    "with torch.no_grad():\n",
    "    y_pred_linear1_val = model_linear1(X).cpu().numpy()\n",
    "    y_pred_linear_val = model_linear(X, X_pair).cpu().numpy()\n",
    "\n",
    "# Compute metrics for Linear_order1\n",
    "residual1 = fitness_np - y_pred_linear1_val\n",
    "mae_linear1 = np.mean(np.abs(residual1 * weight_np))\n",
    "r_linear1_calc, p_linear1_calc = pearsonr(fitness_np, y_pred_linear1_val)\n",
    "\n",
    "# Compute metrics for Linear (with pairs)\n",
    "residual_linear = fitness_np - y_pred_linear_val\n",
    "mae_linear = np.mean(np.abs(residual_linear * weight_np))\n",
    "r_linear_calc, p_linear_calc = pearsonr(fitness_np, y_pred_linear_val)\n",
    "\n",
    "# Sparsity\n",
    "nnz_phi_pair = (np.abs(model_linear.phi_pair.detach().cpu().numpy()) > 1e-10).sum()\n",
    "sparsity_pct = 100 * (1 - nnz_phi_pair / len(model_linear.phi_pair.detach().cpu().numpy()))\n",
    "\n",
    "print(f\"  Linear (single): r={r_linear1_calc:.4f}, MAE={mae_linear1:.6f}\")\n",
    "print(f\"  Linear (pairs): r={r_linear_calc:.4f}, MAE={mae_linear:.6f}, Sparsity={sparsity_pct:.2f}%\\n\")\n",
    "\n",
    "# ========= 1. ‰øùÂ≠òÂèØËßÜÂåñÂõæË°® =========\n",
    "print(\"üìä Saving visualization figures...\")\n",
    "\n",
    "# Figure 1: ËÆ≠ÁªÉÊçüÂ§±Êõ≤Á∫øÔºàÂ¶ÇÊûúËÆ≠ÁªÉÂéÜÂè≤ÂèØÁî®Ôºâ\n",
    "try:\n",
    "    fig1, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    if 'loss_history1' in dir() and loss_history1:\n",
    "        epoch_list1 = list(range(0, len(loss_history1) * 10, 10))\n",
    "    else:\n",
    "        epoch_list1 = []\n",
    "    \n",
    "    if 'loss_history2' in dir() and loss_history2:\n",
    "        epoch_list2 = list(range(0, len(loss_history2) * 10, 10))\n",
    "    else:\n",
    "        epoch_list2 = []\n",
    "\n",
    "    ax = axes[0, 0]\n",
    "    if epoch_list1 and 'loss_history1' in dir():\n",
    "        ax.plot(epoch_list1, loss_history1, linewidth=2, color='steelblue', label='Order 1', alpha=0.8)\n",
    "    if epoch_list2 and 'loss_history2' in dir():\n",
    "        ax.plot(epoch_list2, loss_history2, linewidth=2, color='coral', label='Order 2 (Total)', alpha=0.8)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.set_title('Training Loss Comparison', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[0, 1]\n",
    "    if 'data_loss_history' in dir() and 'l1_loss_history' in dir() and data_loss_history and l1_loss_history:\n",
    "        ax.plot(epoch_list2[:len(data_loss_history)], data_loss_history, linewidth=2, color='green', label='Data Loss', alpha=0.8)\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(epoch_list2[:len(l1_loss_history)], l1_loss_history, linewidth=2, color='red', label='L1 Penalty', alpha=0.8, linestyle='--')\n",
    "        ax.set_ylabel('Data Loss', fontsize=12, color='green')\n",
    "        ax2.set_ylabel('L1 Penalty', fontsize=12, color='red')\n",
    "        ax.tick_params(axis='y', labelcolor='green')\n",
    "        ax2.tick_params(axis='y', labelcolor='red')\n",
    "        ax.legend(loc='upper left', fontsize=11)\n",
    "        ax2.legend(loc='upper right', fontsize=11)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_title('Loss Decomposition (Order 2)', fontsize=13, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[1, 0]\n",
    "    if epoch_list1 and 'loss_history1' in dir():\n",
    "        ax.semilogy(epoch_list1, loss_history1, linewidth=2, color='steelblue', label='Order 1', alpha=0.8)\n",
    "    if epoch_list2 and 'loss_history2' in dir():\n",
    "        ax.semilogy(epoch_list2, loss_history2, linewidth=2, color='coral', label='Order 2', alpha=0.8)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss (log scale)', fontsize=12)\n",
    "    ax.set_title('Training Loss (Log Scale)', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(alpha=0.3, which='both')\n",
    "\n",
    "    ax = axes[1, 1]\n",
    "    if 'data_loss_history' in dir() and data_loss_history:\n",
    "        ax.semilogy(epoch_list2[:len(data_loss_history)], data_loss_history, linewidth=2, color='green', alpha=0.8)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Data Loss (log scale)', fontsize=12)\n",
    "    ax.set_title('Data Loss Only (Log Scale)', fontsize=13, fontweight='bold')\n",
    "    ax.grid(alpha=0.3, which='both')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig1.savefig(f\"{results_dir}/01_training_loss.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì 01_training_loss.png\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save training loss figure: {e}\")\n",
    "\n",
    "# Figure 2: Order 1 vs Order 2 ÂØπÊØî\n",
    "try:\n",
    "    fig2, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    ax = axes[0, 0]\n",
    "    hb = ax.hexbin(df[\"fitness\"], df[\"predicted_fitness_order1\"], gridsize=120, cmap='viridis', mincnt=1, edgecolors='none')\n",
    "    ax.set_xlabel(\"Measured fitness\", fontsize=12)\n",
    "    ax.set_ylabel(\"Predicted fitness\", fontsize=12)\n",
    "    ax.set_title(f\"Order 1 Model - Density\\nPearson r={r1:.4f}\" if 'r1' in dir() else \"Order 1 Model - Density\", fontsize=13, fontweight='bold')\n",
    "    ax.axis('equal')\n",
    "    ax.set_xlim(df[\"fitness\"].min(), df[\"fitness\"].max())\n",
    "    ax.set_ylim(df[\"fitness\"].min(), df[\"fitness\"].max())\n",
    "    plt.colorbar(hb, ax=ax, label='Density')\n",
    "\n",
    "    ax = axes[0, 1]\n",
    "    ax.scatter(df[\"fitness\"], df[\"predicted_fitness_order1\"], c=df[\"weight\"], s=5, cmap='plasma', alpha=0.6, edgecolors='none')\n",
    "    ax.set_xlabel(\"Measured fitness\", fontsize=12)\n",
    "    ax.set_ylabel(\"Predicted fitness\", fontsize=12)\n",
    "    ax.set_title(f\"Order 1 Model - Weight\\nPearson r={r1:.4f}\" if 'r1' in dir() else \"Order 1 Model - Weight\", fontsize=13, fontweight='bold')\n",
    "    ax.axis('equal')\n",
    "    ax.set_xlim(df[\"fitness\"].min(), df[\"fitness\"].max())\n",
    "    ax.set_ylim(df[\"fitness\"].min(), df[\"fitness\"].max())\n",
    "\n",
    "    ax = axes[1, 0]\n",
    "    hb = ax.hexbin(df[\"fitness\"], df[\"predicted_fitness_order2\"], gridsize=120, cmap='viridis', mincnt=1, edgecolors='none')\n",
    "    ax.set_xlabel(\"Measured fitness\", fontsize=12)\n",
    "    ax.set_ylabel(\"Predicted fitness\", fontsize=12)\n",
    "    ax.set_title(f\"Order 2 Model - Density\\nPearson r={r2:.4f}\" if 'r2' in dir() else \"Order 2 Model - Density\", fontsize=13, fontweight='bold')\n",
    "    ax.axis('equal')\n",
    "    ax.set_xlim(df[\"fitness\"].min(), df[\"fitness\"].max())\n",
    "    ax.set_ylim(df[\"fitness\"].min(), df[\"fitness\"].max())\n",
    "    plt.colorbar(hb, ax=ax, label='Density')\n",
    "\n",
    "    ax = axes[1, 1]\n",
    "    ax.scatter(df[\"fitness\"], df[\"predicted_fitness_order2\"], c=df[\"weight\"], s=5, cmap='plasma', alpha=0.6, edgecolors='none')\n",
    "    ax.set_xlabel(\"Measured fitness\", fontsize=12)\n",
    "    ax.set_ylabel(\"Predicted fitness\", fontsize=12)\n",
    "    ax.set_title(f\"Order 2 Model - Weight\\nPearson r={r2:.4f}\" if 'r2' in dir() else \"Order 2 Model - Weight\", fontsize=13, fontweight='bold')\n",
    "    ax.axis('equal')\n",
    "    ax.set_xlim(df[\"fitness\"].min(), df[\"fitness\"].max())\n",
    "    ax.set_ylim(df[\"fitness\"].min(), df[\"fitness\"].max())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig2.savefig(f\"{results_dir}/02_order1_vs_order2.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì 02_order1_vs_order2.png\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save Order 1 vs 2 figure: {e}\")\n",
    "\n",
    "# Figure 3: Order 2 ÂèÇÊï∞ÂàÜÂ∏É\n",
    "try:\n",
    "    theta_vals = model2.theta.detach().cpu().numpy()\n",
    "    phi_pair_vals = model2.phi_pair.detach().cpu().numpy()\n",
    "    fig3, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    ax = axes[0, 0]\n",
    "    ax.hist(theta_vals, bins=100, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Parameter value', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_title(f'Single Mutations (theta)\\nN={len(theta_vals)}, Mean={theta_vals.mean():.4f}', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[0, 1]\n",
    "    ax.hist(phi_pair_vals, bins=100, edgecolor='black', alpha=0.7, color='coral')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Parameter value', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_title(f'Pairwise Interactions (phi_pair)\\nN={len(phi_pair_vals)}, Mean={phi_pair_vals.mean():.4f}', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[1, 0]\n",
    "    sorted_theta = np.sort(theta_vals)\n",
    "    ax.plot(sorted_theta, linewidth=1.5, color='steelblue')\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax.set_xlabel('Feature index (sorted)', fontsize=12)\n",
    "    ax.set_ylabel('Parameter value', fontsize=12)\n",
    "    ax.set_title('Sorted Single Mutation Parameters', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[1, 1]\n",
    "    sorted_phi = np.sort(phi_pair_vals)\n",
    "    ax.plot(sorted_phi, linewidth=1.5, color='coral')\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax.set_xlabel('Feature index (sorted)', fontsize=12)\n",
    "    ax.set_ylabel('Parameter value', fontsize=12)\n",
    "    ax.set_title('Sorted Pairwise Interaction Parameters', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig3.savefig(f\"{results_dir}/03_order2_parameters.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì 03_order2_parameters.png\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save Order 2 parameters figure: {e}\")\n",
    "\n",
    "# Figure 4: ÂõõÊ®°ÂûãÂØπÊØîÔºàOrder 1, Order 2, Linear pairs, Linear singleÔºâ\n",
    "try:\n",
    "    fig4, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_p1, _ = model1(X)\n",
    "        y_p1 = y_p1.cpu().numpy()\n",
    "        _, phi2 = model2(X, X_pair)\n",
    "        y_p2 = (1.0 / (1.0 + torch.exp(torch.clamp(phi2 / (8.314 * 303.0), -50, 50)))).cpu().numpy()\n",
    "        y_p2 = model2.a.item() * y_p2 + model2.b.item()\n",
    "\n",
    "    r1_tmp, p1_tmp = pearsonr(fitness_np, y_p1)\n",
    "    r2_tmp, p2_tmp = pearsonr(fitness_np, y_p2)\n",
    "\n",
    "    models_data = [\n",
    "        (\"Order 1\\n(Single muts)\", y_p1, r1_tmp),\n",
    "        (\"Order 2\\n(With pairs)\", y_p2, r2_tmp),\n",
    "        (\"Linear\\n(Pairs)\", y_pred_linear, r_linear_calc),\n",
    "        (\"Linear\\n(Single)\", y_pred_linear1_val, r_linear1_calc)\n",
    "    ]\n",
    "\n",
    "    # Compute y-axis limits SEPARATELY for each model to avoid compression\n",
    "    model_ylims_4 = []\n",
    "    for col, (name, y_pred, r) in enumerate(models_data):\n",
    "        y_min = y_pred.min()\n",
    "        y_max = y_pred.max()\n",
    "        y_margin = (y_max - y_min) * 0.1 if (y_max - y_min) > 0 else 0.1\n",
    "        model_ylims_4.append((y_min - y_margin, y_max + y_margin))\n",
    "\n",
    "    # Top row: hexbin density plots\n",
    "    for col, (name, y_pred, r) in enumerate(models_data):\n",
    "        ax = axes[0, col]\n",
    "        hb = ax.hexbin(fitness_np, y_pred, gridsize=100, cmap='viridis', mincnt=1, edgecolors='none')\n",
    "        ax.plot([fitness_np.min(), fitness_np.max()], [fitness_np.min(), fitness_np.max()], 'r--', linewidth=2, alpha=0.7)\n",
    "        ax.set_xlabel(\"Measured fitness\", fontsize=11)\n",
    "        ax.set_ylabel(\"Predicted fitness\", fontsize=11)\n",
    "        ax.set_title(f\"{name}\\nr={r:.4f}\", fontsize=12, fontweight='bold')\n",
    "        ax.set_xlim(fitness_np.min(), fitness_np.max())\n",
    "        # Use individual model's y-limits for clearer visualization\n",
    "        ax.set_ylim(model_ylims_4[col])\n",
    "        plt.colorbar(hb, ax=ax, label='Density')\n",
    "\n",
    "    # Bottom row: weight-colored scatter plots\n",
    "    for col, (name, y_pred, r) in enumerate(models_data):\n",
    "        ax = axes[1, col]\n",
    "        scatter = ax.scatter(fitness_np, y_pred, c=weight_np, s=2, cmap='plasma', alpha=0.6, edgecolors='none')\n",
    "        ax.plot([fitness_np.min(), fitness_np.max()], [fitness_np.min(), fitness_np.max()], 'r--', linewidth=2, alpha=0.7)\n",
    "        ax.set_xlabel(\"Measured fitness\", fontsize=11)\n",
    "        ax.set_ylabel(\"Predicted fitness\", fontsize=11)\n",
    "        ax.set_title(f\"Weight distribution\", fontsize=11)\n",
    "        ax.set_xlim(fitness_np.min(), fitness_np.max())\n",
    "        # Use individual model's y-limits\n",
    "        ax.set_ylim(model_ylims_4[col])\n",
    "        plt.colorbar(scatter, ax=ax, label='Weight')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig4.savefig(f\"{results_dir}/04_four_models_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì 04_four_models_comparison.png\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save four models comparison figure: {e}\")\n",
    "\n",
    "# Figure 5: Á∫øÊÄßÊ®°ÂûãÂèÇÊï∞ÂàÜÂ∏ÉÔºàÂåÖÊã¨ Linear_order1Ôºâ\n",
    "try:\n",
    "    fig5, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    theta_linear1 = model_linear1.theta.detach().cpu().numpy()\n",
    "    ax = axes[0, 0]\n",
    "    ax.hist(theta_linear1, bins=80, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Parameter value', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_title(f'Linear_order1: Single Mutations\\nN={len(theta_linear1)}', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    theta_linear = model_linear.theta.detach().cpu().numpy()\n",
    "    phi_pair_linear = model_linear.phi_pair.detach().cpu().numpy()\n",
    "    ax = axes[0, 1]\n",
    "    ax.hist(phi_pair_linear, bins=80, edgecolor='black', alpha=0.7, color='coral')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Parameter value', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_title(f'Linear (pairs): Pairwise Interactions\\nN={len(phi_pair_linear)}', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[1, 0]\n",
    "    sorted_t1 = np.sort(theta_linear1)\n",
    "    ax.plot(sorted_t1, linewidth=1.5, color='steelblue', label='Linear_order1')\n",
    "    sorted_t2 = np.sort(theta_linear)\n",
    "    ax.plot(sorted_t2, linewidth=1.5, color='orange', label='Linear (pairs)', alpha=0.7)\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax.set_xlabel('Feature index (sorted)', fontsize=12)\n",
    "    ax.set_ylabel('Parameter value', fontsize=12)\n",
    "    ax.set_title('Sorted Single Mutation Parameters Comparison', fontsize=13)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[1, 1]\n",
    "    sorted_p = np.sort(phi_pair_linear)\n",
    "    ax.plot(sorted_p, linewidth=1.5, color='coral')\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax.fill_between(range(len(sorted_p)), sorted_p, 0, alpha=0.3, color='coral')\n",
    "    ax.set_xlabel('Feature index (sorted)', fontsize=12)\n",
    "    ax.set_ylabel('Parameter value', fontsize=12)\n",
    "    ax.set_title('Sorted Pairwise Interaction Parameters (Linear)', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig5.savefig(f\"{results_dir}/05_linear_model_parameters.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  ‚úì 05_linear_model_parameters.png\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save linear model parameters figure: {e}\")\n",
    "\n",
    "# ========= 2. ‰øùÂ≠òÊ®°ÂûãÂèÇÊï∞CSV =========\n",
    "print(\"\\nüìã Saving parameter CSV files...\")\n",
    "\n",
    "# Save Linear_order1 parameters (single mutations only)\n",
    "linear1_theta = pd.DataFrame({'mutation': all_mutations, 'theta_linear1': model_linear1.theta.detach().cpu().numpy()})\n",
    "linear1_theta.to_csv(f\"{results_dir}/linear1_theta.csv\", index=False)\n",
    "print(f\"  ‚úì linear1_theta.csv\")\n",
    "\n",
    "# Save Linear model (with pairs) parameters if available\n",
    "try:\n",
    "    linear_theta_df = pd.DataFrame({'mutation': all_mutations, 'theta': model_linear.theta.detach().cpu().numpy()})\n",
    "    linear_phi_pair_df = pd.DataFrame({'pair_idx': range(len(filtered_pairs)), 'phi_pair': model_linear.phi_pair.detach().cpu().numpy()})\n",
    "    linear_theta_df.to_csv(f\"{results_dir}/linear_theta.csv\", index=False)\n",
    "    linear_phi_pair_df.to_csv(f\"{results_dir}/linear_phi_pair.csv\", index=False)\n",
    "    print(f\"  ‚úì linear_theta.csv\")\n",
    "    print(f\"  ‚úì linear_phi_pair.csv\")\n",
    "except:\n",
    "    print(f\"  ‚ö† Could not save linear (pairs) parameters\")\n",
    "\n",
    "# ========= 3. ‰øùÂ≠òÈ¢ÑÊµãÁªìÊûú =========\n",
    "print(\"\\nüìä Saving predictions...\")\n",
    "try:\n",
    "    predictions_df_save = df[['aa_seq', 'fitness', 'predicted_fitness_linear', 'predicted_fitness_linear1', 'weight']].copy()\n",
    "    predictions_df_save.to_csv(f\"{results_dir}/predictions_linear_models.csv\", index=False)\n",
    "    print(f\"  ‚úì predictions_linear_models.csv ({len(predictions_df_save)} sequences)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save predictions: {e}\")\n",
    "\n",
    "# ========= 4. ‰øùÂ≠òÊÄßËÉΩÊåáÊ†á =========\n",
    "print(\"\\nüìà Saving performance metrics...\")\n",
    "try:\n",
    "    perf = {\n",
    "        \"Dataset\": {\n",
    "            \"N_sequences\": int(N),\n",
    "            \"N_mutations\": int(M),\n",
    "            \"N_pairs\": int(P),\n",
    "            \"Filtered_pairs_min_support_3\": int(len(filtered_pairs))\n",
    "        },\n",
    "        \"Linear_single\": {\n",
    "            \"Model\": \"Linear, single-mutation only (LASSO)\",\n",
    "            \"Description\": \"Uses LASSO to fit only single-mutation features (no pairwise interactions)\",\n",
    "            \"Pearson_r\": float(r_linear1_calc),\n",
    "            \"p_value\": float(p_linear1_calc),\n",
    "            \"MAE_weighted\": float(mae_linear1),\n",
    "            \"NNZ_theta\": int((np.abs(model_linear1.theta.detach().cpu().numpy()) > 1e-10).sum()),\n",
    "            \"N_theta\": int(len(model_linear1.theta.detach().cpu().numpy()))\n",
    "        },\n",
    "        \"Linear_pairs\": {\n",
    "            \"Model\": \"Linear, with pairwise interactions (LASSO)\",\n",
    "            \"Description\": \"Uses LASSO to fit single-mutation and pairwise epistasis features\",\n",
    "            \"Pearson_r\": float(r_linear_calc),\n",
    "            \"p_value\": float(p_linear_calc),\n",
    "            \"MAE_weighted\": float(mae_linear),\n",
    "            \"Sparsity_percent\": float(sparsity_pct),\n",
    "            \"NNZ_theta\": int((np.abs(model_linear.theta.detach().cpu().numpy()) > 1e-10).sum()),\n",
    "            \"NNZ_phi_pair\": int(nnz_phi_pair)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(f\"{results_dir}/performance_metrics.json\", 'w') as f:\n",
    "        json.dump(perf, f, indent=2)\n",
    "    print(f\"  ‚úì performance_metrics.json\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save performance metrics: {e}\")\n",
    "\n",
    "# ========= 5. ‰øùÂ≠òÊ®°ÂûãÊ£ÄÊü•ÁÇπ =========\n",
    "print(\"\\nü§ñ Saving model checkpoints...\")\n",
    "try:\n",
    "    torch.save(model_linear1.state_dict(), f\"{results_dir}/model_linear1_checkpoint.pth\")\n",
    "    print(f\"  ‚úì model_linear1_checkpoint.pth (Linear single-mutation model)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save model_linear1: {e}\")\n",
    "\n",
    "try:\n",
    "    torch.save(model_linear.state_dict(), f\"{results_dir}/model_linear_checkpoint.pth\")\n",
    "    print(f\"  ‚úì model_linear_checkpoint.pth (Linear with-pairs model)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save model_linear: {e}\")\n",
    "\n",
    "# ========= 6. ‰øùÂ≠òREADME =========\n",
    "print(\"\\nüìù Saving README...\")\n",
    "try:\n",
    "    readme = f\"\"\"# MoCHI Model Training Results - Linear & MoCHI Models\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Summary\n",
    "This results folder contains comprehensive training results including:\n",
    "- **MoCHI Models**: Order 1 (non-linear, single muts), Order 2 (non-linear, with pairs)\n",
    "- **Linear Models**: Linear_order1 (single muts only), Linear (with pairs) - both trained via LASSO\n",
    "\n",
    "## Dataset Summary\n",
    "- Total sequences: {N}\n",
    "- Single mutations (M): {M}\n",
    "- Pairwise mutations (P): {P}\n",
    "- Filtered pairs (min_support=3): {len(filtered_pairs)}\n",
    "\n",
    "## Files\n",
    "\n",
    "### Visualizations (5 PNG files)\n",
    "- **01_training_loss.png**: Training dynamics for Order 1 & 2 models (loss curves)\n",
    "- **02_order1_vs_order2.png**: MoCHI model comparison with density and weight plots\n",
    "- **03_order2_parameters.png**: Parameter distributions for MoCHI Order 2\n",
    "- **04_four_models_comparison.png**: All 4 models side-by-side (Order 1, Order 2, Linear pairs, Linear single)\n",
    "- **05_linear_model_parameters.png**: Parameter distributions for Linear models\n",
    "\n",
    "### Parameters (3 CSV files)\n",
    "- **linear1_theta.csv**: Linear_order1 single-mutation parameters ({len(linear1_theta)} mutations)\n",
    "- **linear_theta.csv**: Linear (with pairs) single-mutation parameters\n",
    "- **linear_phi_pair.csv**: Linear (with pairs) pairwise interaction parameters\n",
    "\n",
    "### Results\n",
    "- **predictions_linear_models.csv**: Full predictions for all {N} sequences\n",
    "- **performance_metrics.json**: Quantitative performance comparison\n",
    "\n",
    "### Models\n",
    "- **model_linear1_checkpoint.pth**: Linear_order1 weights (single-mutation only)\n",
    "- **model_linear_checkpoint.pth**: Linear model weights (with pairwise interactions)\n",
    "\n",
    "## Performance Comparison\n",
    "\n",
    "| Model | Type | Pearson r | MAE | Sparsity |\n",
    "|-------|------|-----------|-----|----------|\n",
    "| Linear (single) | LASSO, M only | {r_linear1_calc:.4f} | {mae_linear1:.6f} | N/A |\n",
    "| Linear (pairs) | LASSO, M+P | {r_linear_calc:.4f} | {mae_linear:.6f} | {sparsity_pct:.2f}% |\n",
    "\n",
    "## Key Results\n",
    "\n",
    "### Linear Models\n",
    "- **Linear_order1** (r={r_linear1_calc:.4f}): Uses only single mutations without epistasis\n",
    "- **Linear with pairs** (r={r_linear_calc:.4f}): Adds pairwise interactions\n",
    "  - Correlation improvement: +{(r_linear_calc/r_linear1_calc-1)*100:.2f}%\n",
    "  - MAE reduction: {(1-mae_linear/mae_linear1)*100:.1f}% (from {mae_linear1:.4f} ‚Üí {mae_linear:.4f})\n",
    "  - Sparsity: {sparsity_pct:.2f}% sparse in phi_pair (via LASSO L1)\n",
    "\n",
    "## Model Architectures\n",
    "\n",
    "### Linear_order1 (Single-mutation only)\n",
    "```\n",
    "yhat = phi0 + X @ theta\n",
    "```\n",
    "\n",
    "### Linear (with Pairwise)\n",
    "```\n",
    "yhat = phi0 + X @ theta + X_pair @ phi_pair\n",
    "```\n",
    "\n",
    "## Notes\n",
    "- All linear models use weighted least squares fitting\n",
    "- LASSO regularization (L1 penalty) automatically induces sparsity\n",
    "- Grid search over alpha values to find optimal regularization strength\n",
    "\"\"\"\n",
    "\n",
    "    with open(f\"{results_dir}/README.md\", 'w') as f:\n",
    "        f.write(readme)\n",
    "    print(f\"  ‚úì README.md\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö† Could not save README: {e}\")\n",
    "\n",
    "# ========= 7. ÊúÄÁªàÁªüËÆ° =========\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ All results saved successfully!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüìÅ Location: {os.path.abspath(results_dir)}\")\n",
    "print(f\"\\nüìä Files generated ({len(os.listdir(results_dir))} total):\")\n",
    "\n",
    "file_stats = {}\n",
    "for fname in sorted(os.listdir(results_dir)):\n",
    "    fpath = os.path.join(results_dir, fname)\n",
    "    size = os.path.getsize(fpath)\n",
    "    file_stats[fname] = size\n",
    "    size_mb = size / (1024**2)\n",
    "    if size < 1024:\n",
    "        print(f\"  ‚Ä¢ {fname:<40} {size:>10} B\")\n",
    "    elif size < 1024**2:\n",
    "        print(f\"  ‚Ä¢ {fname:<40} {size/1024:>10.2f} KB\")\n",
    "    else:\n",
    "        print(f\"  ‚Ä¢ {fname:<40} {size_mb:>10.2f} MB\")\n",
    "\n",
    "total_size = sum(file_stats.values()) / (1024**2)\n",
    "print(f\"\\nüì¶ Total size: {total_size:.2f} MB\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ========= 8. Ê®°ÂûãÊÄßËÉΩÊÄªÁªì =========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Model Performance Summary\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Linear_order1 (single mutations only):\")\n",
    "print(f\"  Pearson r: {r_linear1_calc:.6f}\")\n",
    "print(f\"  MAE (weighted): {mae_linear1:.6f}\")\n",
    "print(f\"  Non-zero parameters: {int((np.abs(model_linear1.theta.detach().cpu().numpy()) > 1e-10).sum())}/{M}\")\n",
    "print(f\"\\nLinear (with pairwise interactions):\")\n",
    "print(f\"  Pearson r: {r_linear_calc:.6f}\")\n",
    "print(f\"  MAE (weighted): {mae_linear:.6f}\")\n",
    "print(f\"  Sparsity (phi_pair): {sparsity_pct:.2f}%\")\n",
    "print(f\"  Non-zero single mutations: {int((np.abs(model_linear.theta.detach().cpu().numpy()) > 1e-10).sum())}/{M}\")\n",
    "print(f\"  Non-zero pairwise: {int(nnz_phi_pair)}/{len(filtered_pairs)}\")\n",
    "print(f\"\\nImprovement (single ‚Üí pairs):\")\n",
    "print(f\"  Pearson r improvement: +{(r_linear_calc - r_linear1_calc):.6f} ({(r_linear_calc/r_linear1_calc - 1)*100:.2f}%)\")\n",
    "print(f\"  MAE reduction: {(mae_linear1 - mae_linear):.6f} ({(1 - mae_linear/mae_linear1)*100:.2f}% better)\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
